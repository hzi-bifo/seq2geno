Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	compute_gpa_table
	2

rule compute_gpa_table:
    input: tmp/roary/gene_presence_absence.csv
    output: /net/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/results/gpa.tab
    jobid: 1

    Error in rule compute_gpa_table:
        jobid: 1
        output: /net/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/results/gpa.tab

RuleException:
CalledProcessError in line 12 of /net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/CREATE_GPA_TABLE.smk:
Command ' set -euo pipefail;  Rscript /net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/.snakemake.jnzwphdb.roary_gpa2bin.R ' returned non-zero exit status 127.
  File "/net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/CREATE_GPA_TABLE.smk", line 12, in __rule_compute_gpa_table
  File "/home/thkuo/miniconda3/envs/phypal/lib/python3.6/concurrent/futures/thread.py", line 55, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/.snakemake/log/2018-07-13T120243.906780.snakemake.log
