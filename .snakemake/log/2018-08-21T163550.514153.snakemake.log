Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	all_snps_list
	1	covert_snps_table
	1	create_dict_file
	1	nonsyn_snps_table
	1	syn_snps_table
	6

[Tue Aug 21 16:35:55 2018]
rule create_dict_file:
    input: CH2500.flt.vcf, CH2502.flt.vcf, CH2522.flt.vcf, F1659.flt.vcf
    output: dict.txt
    jobid: 7

    [Tue Aug 21 16:35:55 2018]
    Error in rule create_dict_file:
        jobid: 7
        output: dict.txt

RuleException:
CalledProcessError in line 90 of /net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v5/CREATE_SNPS_TABLE.smk:
Command ' set -euo pipefail;  
        echo CH2500.flt.vcf CH2502.flt.vcf CH2522.flt.vcf F1659.flt.vcf|         sed 's/\.flt\.vcf\W*/
/g' > dict.txt ' returned non-zero exit status 1.
  File "/net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v5/CREATE_SNPS_TABLE.smk", line 90, in __rule_create_dict_file
  File "/home/thkuo/miniconda3/envs/seq2geno/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Removing output files of failed job create_dict_file since they might be corrupted:
dict.txt
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v5/.snakemake/log/2018-08-21T163550.514153.snakemake.log
