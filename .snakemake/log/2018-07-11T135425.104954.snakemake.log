Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	create_and_make_expr_table
	2

rule create_and_make_expr_table:
    input: tmp/rpg_dict
    output: /net/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/results/expr.tab
    jobid: 3

    Error in rule create_and_make_expr_table:
        jobid: 3
        output: /net/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/results/expr.tab

RuleException:
CalledProcessError in line 100 of /net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/CREATE_EXPR_TABLE.smk:
Command ' set -euo pipefail;  Rscript /net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/.snakemake.tuty29ck.collect_rpg_data.R ' returned non-zero exit status 127.
  File "/net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/CREATE_EXPR_TABLE.smk", line 100, in __rule_create_and_make_expr_table
  File "/home/thkuo/miniconda3/envs/phypal/lib/python3.6/concurrent/futures/thread.py", line 55, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v3/.snakemake/log/2018-07-11T135425.104954.snakemake.log
