Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	last
	1	middle_to_expand
	1	source_information
	4

rule source_information:
    input: fam.list
    output: {*}.fa (dynamic)
    jobid: 3

Subsequent jobs will be added dynamically depending on the output of this job
Dynamically updating jobs
Finished job 3.
1 of 6 steps (17%) done

rule middle_to_expand:
    input: gene-oops.fa
    output: gene-oops.aln
    jobid: 6
    wildcards: fam=gene-oops

Finished job 6.
2 of 6 steps (33%) done

rule middle_to_expand:
    input: gene-1.fa
    output: gene-1.aln
    jobid: 5
    wildcards: fam=gene-1

Finished job 5.
3 of 6 steps (50%) done

rule middle_to_expand:
    input: gene-2.fa
    output: gene-2.aln
    jobid: 7
    wildcards: fam=gene-2

Finished job 7.
4 of 6 steps (67%) done

rule last:
    input: gene-oops.aln, gene-1.aln, gene-2.aln
    output: aln.list
    jobid: 4

Finished job 4.
5 of 6 steps (83%) done

localrule all:
    input: aln.list
    jobid: 0

Finished job 0.
6 of 6 steps (100%) done
Complete log: /net/sgi/metagenomics/data/from_moni/old.tzuhao/seq2geno/dev_versions/v4/test/.snakemake/log/2018-08-08T101220.738544.snakemake.log
